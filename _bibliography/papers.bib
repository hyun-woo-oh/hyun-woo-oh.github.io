---
---

@inproceedings{oh_soc_2023,
    address = {Durres, Albania},
    title = {An {SoC} {FPGA}-based {Integrated} {Real}-time {Image} {Processor} for {Uncooled} {Infrared} {Focal} {Plane} {Array}},
    abstract = {This paper presents an integrated image processor architecture designed for real-time interfacing and processing of high-resolution thermal video obtained from an uncooled infrared focal plane array (IRFPA) utilizing a modern system-onchip field-programmable gate array (SoC FPGA). Our processor provides a one-chip solution for incorporating non-uniformity correction (NUC) algorithms and contrast enhancement methods (CEM) to be performed seamlessly. We have employed NUC algorithms that utilize multiple coefficients to ensure robust image quality, free from ghosting effects and blurring. These algorithms include polynomial modeling-based thermal drift compensation (TDC), two-point correction (TPC), and run-time discrete flat field correction (FFC). To address the memory bottlenecks originating from the parallel execution of NUC algorithms in real-time, we designed accelerators and parallel caching modules for pixel-wise algorithms based on a multi-parameter polynomial expression. Furthermore, we designed a specialized accelerator architecture to minimize the interrupted time for run-time FFC. The implementation on the XC7Z020CLG400 SoC FPGA with the QuantumRed VR thermal module demonstrates that our image processing module achieves a throughput of 60 frames per second (FPS) when processing 14-bit 640×480 resolution infrared video acquired from an uncooled IRFPA.},
    language = {en},
    booktitle = {{Euromicro} {Conference} on {Digital} {System} {Design} ({DSD})},
    publisher = {IEEE},
    author = {Oh, Hyun Woo and Choi, Cheol-Ho and Cha, Jeong Woo and Choi, Hyunmin and Han, Joon Hwan and Shin, Jung-Ho},
    month = sep,
    year = {2023},
    pages = {1--9},
    
    abbr = {DSD},
    present_type = {oral},
    present_text = {Long},
    selected = {true}
}

@inproceedings{choi_disparity_2023,
    address = {Durres, Albania},
    title = {Disparity {Refinement} {Processor} {Architecture} utilizing {Horizontal} and {Vertical} {Characteristics} for {Stereo} {Vision} {Systems}},
    abstract = {In embedded stereo vision systems based on semiglobal matching, the matching accuracy of the initial disparity map can be degraded because of various factors. To solve this problem, weighted median-based disparity refinement hardware architectures are utilized to improve the matching accuracy. However, for the conventional hardware architectures, there is a trade-off between hardware resource utilization and refinement performance when they are implemented on a field programmable gate array (FPGA). Therefore, in this paper, we propose a hybrid max-median filter and its hardware architecture to improve the refinement performance and reduce hardware resource utilization. To evaluate the refinement performance, we used two public stereo datasets. When using the various window sizes for KITTI 2012 and 2015 stereo benchmark datasets, the proposed hardware architecture showed better matching accuracy performance compared with the conventional hardware architectures. In terms of the hardware resource utilization, when implemented on an FPGA, the proposed hardware architecture has low requirements for all types of hardware resources. That is, the proposed hardware architecture overcomes the trade-off between hardware resource utilization and refinement performance.},
    language = {en},
    booktitle = {{Euromicro} {Conference} on {Digital} {System} {Design} ({DSD})},
    publisher = {IEEE},
    author = {Choi, Cheol-Ho and Oh, Hyun Woo},
    month = sep,
    year = {2023},
    pages = {1--8},
    
    abbr = {DSD},
    present_type = {oral},
    present_text = {Long}
}


@inproceedings{oh_rf2p_2023,
    address = {Vienna, Austria},
    title = {{RF2P}: {A} {Lightweight} {RISC} {Processor} {Optimized} for {Rapid} {Migration} from {IEEE}-754 to {Posit}},
    isbn = {979-8-3503-1175-4},
    abstract = {This paper presents a lightweight processor and evaluation platform for migrating from IEEE-754 to posit arithmetic, with an optimized posit arithmetic unit (PAU) supporting existing floating-point instructions. The PAU features a reconfigurable divider architecture for diverse operating conditions and lightweight square root logic. The platform includes a posit-optimized compiler, divider generator, JTAG environment builder, and programmable logic controller. The experimental results demonstrate the successful execution of legacy IEEE-754 code with a small additional workload and up to 60.09 times the performance improvement through hardware acceleration. Additionally, the PAU and divider consume 11.00\% and 57.87\% fewer LUTs, respectively, compared to the best prior works.},
    language = {en},
    booktitle = {{ACM}/{IEEE} {International} {Symposium} on {Low} {Power} {Electronics} and {Design} ({ISLPED})},
    publisher = {IEEE},
    author = {Oh, Hyun Woo and An, Seongmo and Jeong, Won Sik and Lee, Seung Eun},
    month = aug,
    year = {2023},
    pages = {1--6},
    
    abbr = {ISLPED},
    present_type = {oral},
    pdf = {},
    slides = {},
    selected = {true}
}

@article{oh_design_2023,
    title = {The {Design} of {Optimized} {RISC} {Processor} for {Edge} {Artificial} {Intelligence} {Based} on {Custom} {Instruction} {Set} {Extension}},
    volume = {11},
    issn = {2169-3536},
    url = {https://ieeexplore.ieee.org/document/10124773/},
    doi = {10.1109/ACCESS.2023.3276411},
    abstract = {Edge computing is becoming increasingly popular in artificial intelligence (AI) application development due to the benefits of local execution. One widely used approach to overcome hardware limitations in edge computing is heterogeneous computing, which combines a general-purpose processor with a domain-specific AI processor. However, this approach can be inefficient due to the communication overhead resulting from the complex communication protocol. To avoid communication overhead, the concept of an application-specific instruction set processor based on customizable instruction set architecture (ISA) has emerged. By integrating the AI processor into the processor core, on-chip communication replaces the complex communication protocol. Further, custom instruction set extension (ISE) reduces the number of instructions needed to execute AI applications. In this paper, we propose a uniprocessor system architecture for lightweight AI systems. First, we define the custom ISE to integrate the AI processor and GPP into a single processor, minimizing communication overhead. Next, we designed the processor based on the integrated core architecture, including the base core and the AI core, and implemented the processor on an FPGA. Finally, we evaluated the proposed architecture through simulation and implementation of the processor. The results show that the designed processor consumed 6.62\% more lookup tables and 74\% fewer flip-flops while achieving up to 193.88 times enhanced throughput performance and 52.75 times the energy efficiency compared to the previous system.},
    language = {en},
    journal = {IEEE Access},
    author = {Oh, Hyun Woo and Lee, Seung Eun},
    month = may,
    year = {2023},
    pages = {49409--49421},
    
    abbr = {IEEE Access},
    html = {https://ieeexplore.ieee.org/document/10124773/},
    pdf = {},
    code = {},
    bibtex_show = {true},
    selected = {true}
}

@inproceedings{oh_evaluation_2022,
    address = {Gangneung, Korea},
    title = {Evaluation of {Posit} {Arithmetic} on {Machine} {Learning} based on {Approximate} {Exponential} {Functions}},
    isbn = {978-1-66545-971-6},
    url = {https://ieeexplore.ieee.org/document/10031524/},
    doi = {10.1109/ISOCC56007.2022.10031524},
    abstract = {Recent advances in semiconductor technology lead to ongoing applications to adopt complex techniques based on neural networks. In line with this trend, the concept of optimizing real number arithmetic has been raised. In this paper, we evaluate the performance of the noble number system named posit on neural networks by analyzing the execution of approximate exponential functions, which is fundamental to several activation functions, with posit32 and float32. To implement the functions with posit arithmetic, we designed the software posit library consisting of basic arithmetic operations and conversion operations from/to C standard data types. The result shows that posit arithmetic reduces the average relative error rate by up to 87.12\% on the exponential function.},
    language = {en},
    booktitle = {{International} {SoC} {Design} {Conference} ({ISOCC})},
    publisher = {IEEE},
    author = {Oh, Hyun Woo and Jeong, Won Sik and Lee, Seung Eun},
    month = oct,
    year = {2022},
    pages = {358--359},
    
    abbr = {ISOCC},
    present_type = {poster},
    html = {https://ieeexplore.ieee.org/document/10031524/},
    pdf = {},
    poster = {},
    bibtex_show = {true},
    selected = {true}
}

@article{jeong_edge_2022,
    title = {An {Edge} {AI} {Device} based {Intelligent} {Transportation} {System}},
    volume = {20},
    issn = {2234-8883},
    url = {https://jicce.org/journal/view.html?doi=10.56977/jicce.2022.20.3.166},
    doi = {10.56977/jicce.2022.20.3.166},
    abstract = {Recently, studies have been conducted on intelligent transportation systems (ITS) that provide safety and convenience to humans. Systems that compose the ITS adopt architectures that applied the cloud computing which consists of a highperformance general-purpose processor or graphics processing unit. However, an architecture that only used the cloud computing requires a high network bandwidth and consumes much power. Therefore, applying edge computing to ITS is essential for solving these problems. In this paper, we propose an edge artificial intelligence (AI) device based ITS. Edge AI which is applicable to various systems in ITS has been applied to license plate recognition. We implemented edge AI on a fieldprogrammable gate array (FPGA). The accuracy of the edge AI for license plate recognition was 0.94. Finally, we synthesized the edge AI logic with Magnachip/Hynix 180nm CMOS technology and the power consumption measured using the Synopsys’s design compiler tool was 482.583mW.},
    language = {en},
    number = {3},
    journal = {Journal of Information and Communication Convergence Engineering},
    author = {Jeong, Youngwoo and Oh, Hyun Woo and Kim, Soohee and Lee, Seung Eun},
    month = sep,
    year = {2022},
    pages = {166--173},
    
    abbr = {JICCE},
    html = {https://jicce.org/journal/view.html?doi=10.56977/jicce.2022.20.3.166},
    pdf = {},
    bibtex_show={true}
}

@inproceedings{jeong_intelligent_2022,
    address = {Jeju, Korea},
    title = {Intelligent {Transportation} {System} based on an {Edge} {AI}},
    volume = {13},
    url = {https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11036311},
    abstract = {An intelligent transportation system (ITS) is a future system that combines various technologies to provide safety and convenience to humans. In order to implement ITS, previous systems applied an architecture that contains a large number of data centers with a high-performance general-purpose processor and graphics processing unit to collect the information of vehicles. However, this architecture not only requires a high network bandwidth but also causes the system to decrease power efficiency and makes security weak. In this paper, we propose an ITS based on an edge AI device which solves problems with the existing structure. We applied the edge AI device which is applicable to various systems in ITS to license plate recognition and the highest accuracy was 0.94. We implemented the edge AI device on a field programmable gate array (FPGA) and verified the feasibility of the entire system with the proposed edge AI device.},
    language = {en},
    booktitle = {{International} {Conference} on {Future} {Information} \& {Communication} {Engineering}},
    publisher = {The Korea Institute of Information and Communication Engineering},
    author = {Jeong, Young Woo and Oh, Hyun Woo and Jang, Su Yeon and Lee, Seung Eun},
    month = jan,
    year = {2022},
    pages = {202--206},
    
    abbr = {ICFICE},
    html = {https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11036311},
    pdf = {},
    bibtex_show={true}
}

@inproceedings{cho_local_2022,
    address = {Las Vegas, NV, USA},
    title = {A {Local} {Interconnect} {Network} {Controller} for {Resource}-{Constrained} {Automotive} {Devices}},
    isbn = {978-1-66544-154-4},
    url = {https://ieeexplore.ieee.org/document/9730493/},
    doi = {10.1109/ICCE53296.2022.9730493},
    abstract = {As the amount of data for automotive systems is increased, a dedicated communication controller for in-vehicle networks is required. This paper proposes a local interconnect network (LIN) controller for resource-constrained devices. The designed LIN controller efficiently reduces the workload of target devices by processing the LIN frame header, data response, and protocol errors. To demonstrate the feasibility of design, a Cortex-M0 is employed as a main processor and connected to the LIN controller. We implemented a LIN node by programming the processor, and the functionality of LIN controller was verified with a LIN frame analyzer and hardware scope. In addition, we analyzed the affection of communication loads on the processor and evaluated the benefits of LIN controller.},
    language = {en},
    booktitle = {{IEEE} {International} {Conference} on {Consumer} {Electronics} ({ICCE})},
    publisher = {IEEE},
    author = {Cho, Kwonneung and Oh, Hyun Woo and Kim, Jeongeun and Jeong, Young Woo and Lee, Seung Eun},
    month = jan,
    year = {2022},
    pages = {1--3},
    
    abbr = {ICCE},
    html = {https://ieeexplore.ieee.org/document/9730493/},
    bibtex_show={true}
}

@article{jang_multi-core_2021,
    title = {A {Multi}-{Core} {Controller} for an {Embedded} {AI} {System} {Supporting} {Parallel} {Recognition}},
    volume = {12},
    issn = {2072-666X},
    url = {https://www.mdpi.com/2072-666X/12/8/852},
    doi = {10.3390/mi12080852},
    abstract = {Recent advances in artiﬁcial intelligence (AI) technology encourage the adoption of AI systems for various applications. In most deployments, AI-based computing systems adopt the architecture in which the central server processes most of the data. This characteristic makes the system use a high amount of network bandwidth and can cause security issues. In order to overcome these issues, a new AI model called federated learning was presented. Federated learning adopts an architecture in which the clients take care of data training and transmit only the trained result to the central server. As the data training from the client abstracts and reduces the original data, the system operates with reduced network resources and reinforced data security. A system with federated learning supports a variety of client systems. To build an AI system with resource-limited client systems, composing the client system with multiple embedded AI processors is valid. For realizing the system with this architecture, introducing a controller to arbitrate and utilize the AI processors becomes a stringent requirement. In this paper, we propose an embedded AI system for federated learning that can be composed ﬂexibly with the AI core depending on the application. In order to realize the proposed system, we designed a controller for multiple AI cores and implemented it on a ﬁeld-programmable gate array (FPGA). The operation of the designed controller was veriﬁed through image and speech applications, and the performance was veriﬁed through a simulator.},
    language = {en},
    number = {8},
    journal = {Micromachines},
    author = {Jang, Suyeon and Oh, Hyun Woo and Yoon, Young Hyun and Hwang, Dong Hyun and Jeong, Won Sik and Lee, Seung Eun},
    month = jul,
    year = {2021},
    pages = {852},
    
    abbr = {Micromachines},
    html = {https://www.mdpi.com/2072-666X/12/8/852},
    pdf = {},
    bibtex_show={true}
}

@article{hwang_asimov_2021,
    title = {{ASimOV}: {A} {Framework} for {Simulation} and {Optimization} of an {Embedded} {AI} {Accelerator}},
    volume = {12},
    issn = {2072-666X},
    shorttitle = {{ASimOV}},
    url = {https://www.mdpi.com/2072-666X/12/7/838},
    doi = {10.3390/mi12070838},
    abstract = {Artiﬁcial intelligence algorithms need an external computing device such as a graphics processing unit (GPU) due to computational complexity. For running artiﬁcial intelligence algorithms in an embedded device, many studies proposed light-weighted artiﬁcial intelligence algorithms and artiﬁcial intelligence accelerators. In this paper, we propose the ASimOV framework, which optimizes artiﬁcial intelligence algorithms and generates Verilog hardware description language (HDL) code for executing intelligence algorithms in ﬁeld programmable gate array (FPGA). To verify ASimOV, we explore the performance space of k-NN algorithms and generate Verilog HDL code to demonstrate the k-NN accelerator in FPGA. Our contribution is to provide the artiﬁcial intelligence algorithm as an end-to-end pipeline and ensure that it is optimized to a speciﬁc dataset through simulation, and an artiﬁcial intelligence accelerator is generated in the end.},
    language = {en},
    number = {7},
    journal = {Micromachines},
    author = {Hwang, Dong Hyun and Han, Chang Yeop and Oh, Hyun Woo and Lee, Seung Eun},
    month = jul,
    year = {2021},
    pages = {838},
    
    abbr = {Micromachines},
    html = {https://www.mdpi.com/2072-666X/12/7/838},
    pdf = {},
    bibtex_show={true}
}

@article{oh_design_2021,
    title = {The {Design} of a {2D} {Graphics} {Accelerator} for {Embedded} {Systems}},
    volume = {10},
    issn = {2079-9292},
    url = {https://www.mdpi.com/2079-9292/10/4/469},
    doi = {10.3390/electronics10040469},
    abstract = {Recently, advances in technology have enabled embedded systems to be adopted for a variety of applications. Some of these applications require real-time 2D graphics processing running on limited design speciﬁcations such as low power consumption and a small area. In order to satisfy such conditions, including a speciﬁc 2D graphics accelerator in the embedded system is an effective method. This method reduces the workload of the processor in the embedded system by exploiting the accelerator. The accelerator assists the system to perform 2D graphics processing in real-time. Therefore, a variety of applications that require 2D graphics processing can be implemented with an embedded processor. In this paper, we present a 2D graphics accelerator for tiny embedded systems. The accelerator includes an optimized line-drawing operation based on Bresenham’s algorithm. The optimized operation enables the accelerator to deal with various kinds of 2D graphics processing and to perform the line-drawing instead of the system processor. Moreover, the accelerator also distributes the workload of the processor core by removing the need for the core to access the frame buffer memory. We measure the performance of the accelerator by implementing the processor, including the accelerator, on a ﬁeld-programmable gate array (FPGA), and ascertaining the possibility of realization by synthesizing using the 180 nm CMOS process.},
    language = {en},
    number = {4},
    journal = {Electronics},
    author = {Oh, Hyun Woo and Kim, Ji Kwang and Hwang, Gwan Beom and Lee, Seung Eun},
    month = feb,
    year = {2021},
    pages = {469},
    
    abbr = {Electronics},
    html = {https://www.mdpi.com/2079-9292/10/4/469},
    pdf = {},
    bibtex_show={true}
}

@article{hwang_lossless_2021,
    title = {Lossless {Decompression} {Accelerator} for {Embedded} {Processor} with {GUI}},
    volume = {12},
    issn = {2072-666X},
    url = {https://www.mdpi.com/2072-666X/12/2/145},
    doi = {10.3390/mi12020145},
    abstract = {The development of the mobile industry brings about the demand for high-performance embedded systems in order to meet the requirement of user-centered application. Because of the limitation of memory resource, employing compressed data is efﬁcient for an embedded system. However, the workload for data decompression causes an extreme bottleneck to the embedded processor. One of the ways to alleviate the bottleneck is to integrate a hardware accelerator along with the processor, constructing a system-on-chip (SoC) for the embedded system. In this paper, we propose a lossless decompression accelerator for an embedded processor, which supports LZ77 decompression and static Huffman decoding for an inﬂate algorithm. The accelerator is implemented on a ﬁeld programmable gate array (FPGA) to verify the functional suitability and fabricated in a Samsung 65 nm complementary metal oxide semiconductor (CMOS) process. The performance of the accelerator is evaluated by the Canterbury corpus benchmark and achieved throughput up to 20.7 MB/s at 50 MHz system clock frequency.},
    language = {en},
    number = {2},
    journal = {Micromachines},
    author = {Hwang, Gwan Beom and Cho, Kwon Neung and Han, Chang Yeop and Oh, Hyun Woo and Yoon, Young Hyun and Lee, Seung Eun},
    month = jan,
    year = {2021},
    pages = {145},
    
    abbr = {Micromachines},
    html = {https://www.mdpi.com/2072-666X/12/2/145},
    pdf = {},
    bibtex_show={true}
}

@inproceedings{cho_vision-based_2021,
    address = {Las Vegas, NV, USA},
    title = {Vision-based {Parking} {Occupation} {Detecting} with {Embedded} {AI} {Processor}},
    isbn = {978-1-72819-766-1},
    url = {https://ieeexplore.ieee.org/document/9427661/},
    doi = {10.1109/ICCE50685.2021.9427661},
    abstract = {Recently, as the interest of smart parking system is increasing, the various methods for detecting parking occupation are under study. In this paper, we present a vision-based parking occupation detection with embedded AI processor. By employing a fisheye lens camera, multiple parking slot states are identified in one device. We measure the recognition rate of the AI processor in the proposed system and determine the optimized configuration with software simulator. The highest recognition rate is measured at 94.48\% in the configuration of 64 number of training data with 256 bytes data size.},
    language = {en},
    booktitle = {{IEEE} {International} {Conference} on {Consumer} {Electronics} ({ICCE})},
    publisher = {IEEE},
    author = {Cho, Kwon Neung and Oh, Hyun Woo and Lee, Seung Eun},
    month = jan,
    year = {2021},
    pages = {1--2},
    
    abbr = {ICCE},
    html = {https://ieeexplore.ieee.org/document/9427661/},
    bibtex_show={true}
}

@inproceedings{oh_design_2020,
    address = {Yeosu, Korea},
    title = {Design of 32-bit {Processor} for {Embedded} {Systems}},
    isbn = {978-1-72818-331-2},
    url = {https://ieeexplore.ieee.org/document/9332944/},
    doi = {10.1109/ISOCC50952.2020.9332944},
    abstract = {In this paper, we propose a 32-bit processor for the embedded system. In order to provide less area and low power operation, we adopt MIPS instruction set architecture (ISA) to our processor. The processor consists of five pipeline stages to reduce the critical path. In order to solve the data hazard in pipeline stages, we design the data forwarding unit and stall unit with optimized bubble insertion. The processor is implemented on a field programmable gate array (FPGA), and we verify the functionality of the processor and measure the performance by using the Dhrystone benchmark. The Dhrystone MIPS (DMIPS) is measured at 27.71 at 50 MHz operation.},
    language = {en},
    booktitle = {{International} {SoC} {Design} {Conference} ({ISOCC})},
    publisher = {IEEE},
    author = {Oh, Hyun Woo and Cho, Kwon Neung and Lee, Seung Eun},
    month = oct,
    year = {2020},
    pages = {306--307},
    
    abbr = {ISOCC},
    html = {https://ieeexplore.ieee.org/document/9332944/},
    poster = {},
    selected = {true},
    bibtex_show={true}
}
